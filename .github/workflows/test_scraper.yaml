name: Job Scraper Cron

on:
  schedule:
    - cron: '0 */6 * * *'  # Runs every 6 hours
  workflow_dispatch:  # Allows manual triggering

env:
  DB_PASSWORD: ${{ secrets.DB_PASSWORD }}

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        job_category: [data_engineer, python_developer]

    steps:
    - uses: actions/checkout@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2

    - name: Verify requirements file
      run: |
        ls -la
        echo "Contents of requirements.actions.txt:"
        cat requirements.actions.txt

    - name: Install Docker Compose
      run: |
        sudo curl -L "https://github.com/docker/compose/releases/download/v2.23.3/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        sudo chmod +x /usr/local/bin/docker-compose
        docker-compose --version

    - name: Create directories
      run: |
        mkdir -p data
        mkdir -p error_screenshots
        chmod 777 data error_screenshots

    - name: Build with debug output
      run: docker-compose build --progress=plain scraper

    - name: Start services
      run: |
        docker-compose up -d db flaresolverr
        echo "Waiting for services to be healthy..."
        
        # Wait for services to be ready
        attempts=0
        max_attempts=30
        while [ $attempts -lt $max_attempts ]; do
          if docker-compose ps | grep -q "healthy"; then
            echo "Services are healthy"
            break
          fi
          attempts=$((attempts + 1))
          echo "Attempt $attempts/$max_attempts: Waiting for services..."
          sleep 10
        done
        
        if [ $attempts -eq $max_attempts ]; then
          echo "Services failed to become healthy"
          exit 1
        fi

    - name: Run scraper
      run: |
        docker-compose run --rm scraper python -m app.scrapers.scraper_main \
          --source indeed \
          --category ${{ matrix.job_category }}

    - name: Upload error screenshots
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: error-screenshots-${{ matrix.job_category }}
        path: error_screenshots/
        if-no-files-found: ignore

    - name: Upload scraped data
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: scraped-data-${{ matrix.job_category }}
        path: data/
        if-no-files-found: warn

    - name: Cleanup
      if: always()
      run: |
        docker-compose down -v
        docker system prune -f