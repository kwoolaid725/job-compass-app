name: Job Scraper

on:
  workflow_dispatch:
    inputs:
      run_all:
        description: 'Run all scrapers at once'
        required: false
        default: 'false'

jobs:
  scrape-jobs:
    if: ${{ inputs.run_all != 'true' }}
    runs-on: ubuntu-latest
    env:  # Add environment variables at the job level
      DATABASE_NAME: ${{ secrets.DATABASE_NAME }}
      DATABASE_USERNAME: ${{ secrets.DATABASE_USERNAME }}
      DATABASE_PASSWORD: ${{ secrets.DATABASE_PASSWORD }}
      DATABASE_HOSTNAME: ${{ secrets.DATABASE_HOSTNAME }}
      DATABASE_PORT: ${{ secrets.DATABASE_PORT }}
      LINKEDIN_EMAIL: ${{ secrets.LINKEDIN_EMAIL }}
      LINKEDIN_PASSWORD: ${{ secrets.LINKEDIN_PASSWORD }}

    strategy:
      matrix:
        include:
          - source: "indeed"
            category: "python_developer"
          - source: "indeed"
            category: "data_engineer"
          - source: "linkedin"
            category: "python_developer"
          - source: "linkedin"
            category: "data_engineer"

    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          pip install -r requirements.actions.txt
          playwright install chromium
          sudo apt-get update && sudo apt-get install -y xvfb

      - name: Debug environment variables
        run: |
          echo "Database Host: $DATABASE_HOSTNAME"
          echo "Database Port: $DATABASE_PORT"
          echo "LinkedIn Email: $LINKEDIN_EMAIL"
          echo "LinkedIn Password Length: ${#LINKEDIN_PASSWORD} characters"

      - name: Run scraper for ${{ matrix.source }} - ${{ matrix.category }}
        run: |
          xvfb-run --auto-servernum --server-args="-screen 0 1920x1080x24" python -m app.scrapers.scraper_main --source "${{ matrix.source }}" --category "${{ matrix.category }}" --max_pages 10

  run-all-scrapers:
    if: ${{ inputs.run_all == 'true' }}
    runs-on: ubuntu-latest
    env:
      DATABASE_NAME: ${{ secrets.DATABASE_NAME }}
      DATABASE_USERNAME: ${{ secrets.DATABASE_USERNAME }}
      DATABASE_PASSWORD: ${{ secrets.DATABASE_PASSWORD }}
      DATABASE_HOSTNAME: ${{ secrets.DATABASE_HOSTNAME }}
      DATABASE_PORT: ${{ secrets.DATABASE_PORT }}
      LINKEDIN_EMAIL: ${{ secrets.LINKEDIN_EMAIL }}
      LINKEDIN_PASSWORD: ${{ secrets.LINKEDIN_PASSWORD }}

    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip setuptools
          pip install -r requirements.actions.txt
          playwright install chromium
          sudo apt-get update && sudo apt-get install -y xvfb
      - name: Run all scrapers
        run: |
          xvfb-run --auto-servernum --server-args="-screen 0 1920x1080x24" python -m app.scrapers.scraper_main --run_all --max_pages 10
