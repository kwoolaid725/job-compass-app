name: Job Scraper

on:
  workflow_dispatch:
    inputs:
      run_all:
        description: 'Run all scrapers at once'
        required: false
        default: 'false'
  schedule:
    - cron: '0 0 * * *'  # Runs daily at midnight

jobs:
  scrape-jobs:
    if: ${{ inputs.run_all != 'true' }}
    runs-on: ubuntu-latest
    env:
      LINKEDIN_EMAIL: ${{ secrets.LINKEDIN_EMAIL }}
      LINKEDIN_PASSWORD: ${{ secrets.LINKEDIN_PASSWORD }}
      # Add any other necessary environment variables

    strategy:
      matrix:
        include:
          - source: "indeed"
            category: "python_developer"
          - source: "indeed"
            category: "data_engineer"
          - source: "indeed"
            category: "data_scientist"
          - source: "linkedin"
            category: "python_developer"
          - source: "linkedin"
            category: "data_engineer"
          - source: "linkedin"
            category: "data_scientist"

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            xvfb \
            libnss3 \
            libxss1 \
            libatk-bridge2.0-0 \
            libgbm-dev \
            libgtk-3-0 \
            libxshmfence-dev

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip setuptools wheel
          pip install -r requirements.actions.txt
          playwright install
          playwright install-deps

      - name: Debug Environment
        run: |
          echo "Python version:"
          python --version
          echo "Playwright version:"
          pip show playwright

      - name: Run ${{ matrix.source }} Scraper for ${{ matrix.category }}
        env:
          LINKEDIN_EMAIL: ${{ secrets.LINKEDIN_EMAIL }}
          LINKEDIN_PASSWORD: ${{ secrets.LINKEDIN_PASSWORD }}
        run: |
          xvfb-run --auto-servernum --server-args="-screen 0 1920x1080x24" python -m app.scrapers.scraper_main --source "${{ matrix.source }}" --category "${{ matrix.category }}" --max_pages 10

      - name: Upload scraper artifacts
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: scraper-artifacts-${{ matrix.source }}-${{ matrix.category }}
          path: |
            logs/
            *.log
            *.png
          retention-days: 3

